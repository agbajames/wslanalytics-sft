# HF token not required for TinyLlama (public). Add if you change base model.
HF_TOKEN=

# CPU-friendly base model
BASE_MODEL=TinyLlama/TinyLlama-1.1B-Chat-v1.0

# Where LoRA adapter will be saved
OUT_DIR=artifacts/sft

# Token limits tuned for CPU
MAX_INPUT_TOKENS=1024
MAX_TARGET_TOKENS=384

SEED=42
